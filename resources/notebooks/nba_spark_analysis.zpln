{
  "paragraphs": [
    {
      "user": "anonymous",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://b8b45a7a1a01:4040/jobs/job?id=0",
              "$$hashKey": "object:799"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1734364253957_1052070108",
      "id": "paragraph_1734364253957_1052070108",
      "dateCreated": "2024-12-16T15:50:53+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:533",
      "text": "%pyspark\n\n# Import necessary libraries\nfrom pyspark.sql import SparkSession\n\n# Initialize Spark Session\nspark = SparkSession.builder \\\n    .appName(\"NBA Analysis with Spark\") \\\n    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n    .config(\"spark.sql.catalogImplementation\", \"in-memory\") \\\n    .getOrCreate()\n\n# Define HDFS path\nhdfs_path = \"hdfs://namenode:9000/user/test/output/cleanedData\"\n\n# Load data into DataFrame\ndf = spark.read.csv(hdfs_path, header=False, inferSchema=False)\n\n# Assign column names to match the schema\ncolumn_names = [\n    \"event_id\", \"event_num\", \"game_id\", \"home_description\", \"time\", \"period\",\n    \"player1_id\", \"player1_name\", \"player1_team_abbr\", \"player1_team_city\",\n    \"player1_team_id\", \"player1_team_name\", \"player2_id\", \"player2_name\",\n    \"player2_team_abbr\", \"player2_team_city\", \"player2_team_id\", \"player2_team_name\",\n    \"player3_id\", \"player3_name\", \"player3_team_abbr\", \"player3_team_city\",\n    \"player3_team_id\", \"player3_team_name\", \"score\", \"score_margin\", \"visitor_description\"\n]\ndf = df.toDF(*column_names)",
      "dateUpdated": "2024-12-16T15:52:25+0000",
      "dateFinished": "2024-12-16T15:52:47+0000",
      "dateStarted": "2024-12-16T15:52:25+0000",
      "results": {
        "code": "SUCCESS",
        "msg": []
      }
    },
    {
      "text": "%pyspark\n\nfrom pyspark.sql.functions import col, regexp_extract\nfrom pyspark.sql.functions import when, sum as _sum\n\n# Extract home and visitor scores from the 'score' column in the format 'X - Y'\ndf = df.withColumn(\"home_score\", regexp_extract(col(\"score\"), r\"(\\d+)\\s*-\\s*\\d+\", 1).cast(\"int\")) \\\n       .withColumn(\"visitor_score\", regexp_extract(col(\"score\"), r\"\\d+\\s*-\\s*(\\d+)\", 1).cast(\"int\"))\n\n# Verify the extracted home_score and visitor_score\ndf.select(\"score\", \"home_score\", \"visitor_score\").show(5, truncate=False)\n\n# Aggregate total points scored by player in each game (assuming points are from home or visitor team)\nplayer_game_scores = df.groupBy(\"player1_id\", \"game_id\") \\\n                       .agg(\n                           _sum(when(col(\"home_score\") >= 40, col(\"home_score\")).otherwise(0)).alias(\"total_home_points\"),\n                           _sum(when(col(\"visitor_score\") >= 40, col(\"visitor_score\")).otherwise(0)).alias(\"total_visitor_points\")\n                       )\n\n# Calculate the total points for each player by summing both home and visitor points\nplayer_game_scores = player_game_scores.withColumn(\n    \"total_points\", col(\"total_home_points\") + col(\"total_visitor_points\")\n)\n\n# Filter players who scored 40+ points in a game\nplayers_40_plus = player_game_scores.filter(col(\"total_points\") >= 40).select(\"player1_id\").distinct()\n\n# Calculate the total number of players\ntotal_players = df.select(\"player1_id\").distinct().count()\n\n# Calculate percentage of players scoring 40+ points\npercentage_40_plus = (players_40_plus.count() / total_players) * 100\n\nprint(f\"Percentage of players scoring 40+ points: {percentage_40_plus:.2f}%\")",
      "user": "anonymous",
      "dateUpdated": "2024-12-16T15:52:47+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://b8b45a7a1a01:4040/jobs/job?id=1",
              "$$hashKey": "object:866"
            },
            {
              "jobUrl": "http://b8b45a7a1a01:4040/jobs/job?id=2",
              "$$hashKey": "object:867"
            },
            {
              "jobUrl": "http://b8b45a7a1a01:4040/jobs/job?id=3",
              "$$hashKey": "object:868"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1734364268297_1018772996",
      "id": "paragraph_1734364268297_1018772996",
      "dateCreated": "2024-12-16T15:51:08+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:600",
      "dateFinished": "2024-12-16T15:53:06+0000",
      "dateStarted": "2024-12-16T15:52:47+0000",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------+----------+-------------+\n|score   |home_score|visitor_score|\n+--------+----------+-------------+\n|103 - 93|103       |93           |\n|103 - 91|103       |91           |\n|103 - 89|103       |89           |\n|101 - 89|101       |89           |\n|101 - 86|101       |86           |\n+--------+----------+-------------+\nonly showing top 5 rows\n\nPercentage of players scoring 40+ points: 99.77%\n"
          }
        ]
      }
    },
    {
      "text": "%pyspark\nfrom pyspark.sql.functions import when, countDistinct\n\n# Determine the winning team\ndf = df.withColumn(\"winner_team\", when(col(\"home_score\") > col(\"visitor_score\"), col(\"player1_team_name\"))\n                                  .otherwise(col(\"player2_team_name\")))\n\n# Determine the losing team\ndf = df.withColumn(\"loser_team\", when(col(\"home_score\") < col(\"visitor_score\"), col(\"player1_team_name\"))\n                                  .otherwise(col(\"player2_team_name\")))\n\n# Group by loser_team and count distinct game IDs\nmatches_lost = df.groupBy(\"loser_team\").agg(countDistinct(\"game_id\").alias(\"matches_lost\"))\nmatches_lost.show()",
      "user": "anonymous",
      "dateUpdated": "2024-12-16T15:53:06+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/python",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://b8b45a7a1a01:4040/jobs/job?id=4",
              "$$hashKey": "object:988"
            },
            {
              "jobUrl": "http://b8b45a7a1a01:4040/jobs/job?id=5",
              "$$hashKey": "object:989"
            },
            {
              "jobUrl": "http://b8b45a7a1a01:4040/jobs/job?id=6",
              "$$hashKey": "object:990"
            },
            {
              "jobUrl": "http://b8b45a7a1a01:4040/jobs/job?id=7",
              "$$hashKey": "object:991"
            },
            {
              "jobUrl": "http://b8b45a7a1a01:4040/jobs/job?id=8",
              "$$hashKey": "object:992"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1734364306795_1146018707",
      "id": "paragraph_1734364306795_1146018707",
      "dateCreated": "2024-12-16T15:51:46+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:672",
      "dateFinished": "2024-12-16T15:53:11+0000",
      "dateStarted": "2024-12-16T15:53:06+0000",
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------+------------+\n|loser_team|matches_lost|\n+----------+------------+\n|     Bucks|          82|\n|   Hornets|          82|\n|     Kings|          82|\n|     Bulls|          82|\n| Grizzlies|          82|\n|   Pistons|          82|\n|     Magic|          82|\n|      Jazz|          82|\n|  Warriors|          82|\n|    Pacers|          82|\n|      Nets|          82|\n|     Hawks|          82|\n|  Clippers|          82|\n|   Wizards|          82|\n|   Nuggets|          82|\n|   Unknown|        1107|\n|   Raptors|          82|\n|     76ers|          82|\n|    Knicks|          82|\n| Mavericks|          82|\n+----------+------------+\nonly showing top 20 rows\n\n"
          }
        ]
      }
    }
  ],
  "name": "nba_spark_analysis",
  "id": "2KEMMFVW5",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/nba_spark_analysis"
}