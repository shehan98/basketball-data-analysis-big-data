{
  "metadata": {
    "name": "average_points_prediction_model",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# Import necessary libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, regexp_extract\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\n# Initialize Spark Session\nspark \u003d SparkSession.builder \\\n    .appName(\"NBA Analysis with Spark\") \\\n    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n    .config(\"spark.sql.catalogImplementation\", \"in-memory\") \\\n    .getOrCreate()\n\n# Define HDFS path\nhdfs_path \u003d \"hdfs://namenode:9000/user/test/output/cleanedData\"\n\n# Load data into DataFrame\ndf \u003d spark.read.csv(hdfs_path, header\u003dFalse, inferSchema\u003dFalse)\n\n# Assign column names to match the schema\ncolumn_names \u003d [\n    \"event_id\", \"event_num\", \"game_id\", \"home_description\", \"time\", \"period\",\n    \"player1_id\", \"player1_name\", \"player1_team_abbr\", \"player1_team_city\",\n    \"player1_team_id\", \"player1_team_name\", \"player2_id\", \"player2_name\",\n    \"player2_team_abbr\", \"player2_team_city\", \"player2_team_id\", \"player2_team_name\",\n    \"player3_id\", \"player3_name\", \"player3_team_abbr\", \"player3_team_city\",\n    \"player3_team_id\", \"player3_team_name\", \"score\", \"score_margin\", \"visitor_description\"\n]\ndf \u003d df.toDF(*column_names)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Extract home and visitor scores from \u0027score\u0027 column in \u0027X - Y\u0027 format\ndf \u003d df.withColumn(\"home_score\", regexp_extract(col(\"score\"), r\"(\\d+)\\s*-\\s*\\d+\", 1).cast(\"int\")) \\\n       .withColumn(\"visitor_score\", regexp_extract(col(\"score\"), r\"\\d+\\s*-\\s*(\\d+)\", 1).cast(\"int\"))\n       \ndf \u003d df.withColumn(\"player_points\", col(\"home_score\") + col(\"visitor_score\"))\n\n# Feature Engineering\ndf \u003d df.withColumn(\"score_margin\", col(\"home_score\") - col(\"visitor_score\"))\n\n# Assemble the features into a feature vector\nassembler \u003d VectorAssembler(\n    inputCols\u003d[\"home_score\", \"visitor_score\", \"score_margin\"],  # Add any additional features here\n    outputCol\u003d\"features\"\n)\n\n# Train-Test Split\ntrain_data, test_data \u003d df.randomSplit([0.8, 0.2], seed\u003d1234)\n\n# Initialize a Linear Regression model (for predicting player points)\nlr \u003d LinearRegression(featuresCol\u003d\"features\", labelCol\u003d\"player_points\")\n\n# Create a pipeline with feature assembler and regression model\npipeline \u003d Pipeline(stages\u003d[assembler, lr])\n\n# Fit the model on the training data\nmodel \u003d pipeline.fit(train_data)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Make predictions on the test data\npredictions \u003d model.transform(test_data)\n\n# Evaluate the model performance using RMSE (Root Mean Squared Error)\nevaluator \u003d RegressionEvaluator(labelCol\u003d\"player_points\", predictionCol\u003d\"prediction\", metricName\u003d\"rmse\")\nrmse \u003d evaluator.evaluate(predictions)\n\nprint(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Show predictions\npredictions.select(\"player1_name\", \"prediction\", \"player_points\").show(20, truncate\u003dFalse)"
    }
  ]
}